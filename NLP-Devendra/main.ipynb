{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1661,"status":"ok","timestamp":1743386125718,"user":{"displayName":"Devendra Adhikari","userId":"10654862297012241874"},"user_tz":300},"id":"8l-h-sbb2o2U","outputId":"26e3c706-f4c4-4d86-8728-bb80aa4e8ba8"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from transformers import pipeline, AutoTokenizer\n","from pprint import pprint\n","import warnings\n","warnings.filterwarnings('ignore')\n","import re\n","import torch\n","# from datasets import Dataset\n","import os\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","import nltk\n","\n","# Download NLTK resources (first time only)\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9x95GclD2dMa"},"outputs":[],"source":["def extract_non_blank_answers(text):\n","    # Regular expression to extract Question-Answer pairs\n","    pattern = r'Question:\\s*(.*?)\\s*Answer:\\s*(.*?)\\s*(?=Question:|$)'\n","    matches = re.findall(pattern, text, re.DOTALL)\n","\n","    if matches:\n","      # Filter out where Answer is just a single character or blank ('.' or ' ')\n","      # non_blank_pairs = [(question, answer) for question, answer in matches if len(answer.strip()) > 1]\n","      return_string = ''.join([f\"{question}{answer}\" for question, answer in matches if len(answer.strip())> 1])\n","    else:\n","      return_string = text\n","\n","    # Remove extra whitespace and newlines\n","    return_string = re.sub(r'\\s+', ' ', return_string).strip()\n","\n","    #Remove unnecessary underscores\n","    return_string = re.sub(r'_+', '', return_string)\n","\n","    return return_string\n","\n","# Preprocessing\n","def preprocess(text):\n","    words = [word for word in word_tokenize(text.lower())\n","             if word not in stopwords.words('english')\n","             and word not in string.punctuation\n","             and len(word) > 2]  # Minimum length\n","    return ' '.join(words) if words else '[NO_CONTENT]'\n","\n","\"\"\"\n","  Extracts top n keywords from input text using TF-IDF.\n","\n","  Args:\n","      text (str): Input text to analyze.\n","      n (int): Number of top keywords to return (default=10).\n","\n","  Returns:\n","      list: Top n keywords with highest TF-IDF scores.\n","    \"\"\"\n","def get_top_keywords(text, n=15):\n","    processed_text = preprocess(text)\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform([processed_text])\n","    feature_names = vectorizer.get_feature_names_out()\n","    scores = tfidf_matrix.toarray()[0]\n","    return [feature_names[i] for i in scores.argsort()[::-1][:n]]\n","\n","\n","def truncate_text(text, max_length=512):\n","    \"\"\"Ensure text is within model's token limit\"\"\"\n","    inputs = tokenizer(text, truncation=True, max_length=max_length, return_tensors=\"pt\")\n","    return tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n","\n","def process_batch(batch, batch_size=8):\n","    \"\"\"Process texts in batches with proper truncation\"\"\"\n","    results = []\n","    for i in range(0, len(batch), batch_size):\n","\n","      batch_df = batch.iloc[i:i+batch_size]\n","      batch_texts = batch_df['Refined MSC Notes'].tolist()\n","\n","      # Truncate and analyze\n","      truncated_texts = [truncate_text(text) for text in batch_texts]\n","      sentiments = sentiment_analyzer(truncated_texts)\n","\n","      # Get keywords\n","      keywords = [get_top_keywords(text) for text in truncated_texts]\n","\n","      for idx, (_, row) in enumerate(batch_df.iterrows()):\n","        results.append({\n","            'Match_ID': row['Match ID 18Char'],\n","            'Completion_Date': row['Completion Date'],\n","            # Add other desired fields here\n","            'Cleaned_MSC_Notes': row['Refined MSC Notes'],\n","            'Truncated_text': truncated_texts[idx],\n","            'Sentiment': sentiments[idx]['label'],\n","            'Sentiment_score': sentiments[idx]['score'],\n","            'Keywords': keywords[idx]\n","        })\n","\n","    return pd.DataFrame(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KORiaUwp4mX6","outputId":"75991d20-4791-4c4a-c2c3-baf00aa1466f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]}],"source":["\n","df = pd.read_excel('Training-Restated.xlsx')\n","columns = ['Match Support Contact Notes', 'Completion Date']\n","df = df.dropna(subset=columns)\n","df['Refined MSC Notes'] = df['Match Support Contact Notes'].apply(extract_non_blank_answers)\n","\n","model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","sentiment_analyzer = pipeline(\"sentiment-analysis\",\n","                             model=model_name,\n","                             tokenizer=tokenizer,\n","                             device=0 if torch.cuda.is_available() else -1)\n","\n","result_df = process_batch(df)\n","result_df.head()"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOtviXty5/TY4YyHRjjnmXO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}